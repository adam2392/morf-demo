{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation with AR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot parse: 1:4: cd ../../\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adam2392/Documents/morf-demo/.venv/lib/python3.8/site-packages/lab_black.py\", line 218, in format_cell\n",
      "    formatted_code = _format_code(cell)\n",
      "  File \"/home/adam2392/Documents/morf-demo/.venv/lib/python3.8/site-packages/lab_black.py\", line 29, in _format_code\n",
      "    return format_str(src_contents=code, mode=FileMode())\n",
      "  File \"/home/adam2392/Documents/morf-demo/.venv/lib/python3.8/site-packages/black/__init__.py\", line 974, in format_str\n",
      "    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)\n",
      "  File \"/home/adam2392/Documents/morf-demo/.venv/lib/python3.8/site-packages/black/__init__.py\", line 1083, in lib2to3_parse\n",
      "    raise exc from None\n",
      "black.InvalidInput: Cannot parse: 1:4: cd ../../\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adam2392/Documents\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3 (default, May 19 2020, 18:47:26) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# comparative classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# evaluation classifier\n",
    "from rerf.rerfClassifier import rerfClassifier\n",
    "\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of data sequence\n",
    "ns = np.array([50, 100, 200, 400, 1000])\n",
    "\n",
    "# assume you can train on half trials and\n",
    "# test on half the trials\n",
    "test_size = 0.5\n",
    "\n",
    "# number of samples\n",
    "n_samples = 100\n",
    "\n",
    "# simulated data parameters\n",
    "n_trials = 100\n",
    "\n",
    "# dimensionality of data and noise\n",
    "data_dim = 3\n",
    "noise_dim = 3\n",
    "n_chs = data_dim + noise_dim\n",
    "\n",
    "snr_factor = 1.0\n",
    "\n",
    "# data mean vector\n",
    "mu = np.zeros((data_dim,))\n",
    "\n",
    "# permutation strategy\n",
    "permutation_strategy = \"alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of AR(1) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_random_input_pulse(n_chs, n_steps):\n",
    "    # generate a C x T array\n",
    "    ut = np.zeros((n_chs, n_steps))\n",
    "    \n",
    "    # randomly select a time point around the center\n",
    "    # center_time = n_steps // 2\n",
    "    K = 20\n",
    "    rand_ind = np.random.randint(-K, K, size=None)\n",
    "    ut[:, rand_ind:rand_ind+2] = 1\n",
    "    \n",
    "    # ut[:, center_time:center_time+2] = 1\n",
    "    \n",
    "    return ut\n",
    "\n",
    "def generate_ar_samples2(cls=0, n_steps=1000, k=1):\n",
    "    \"\"\"\n",
    "    Generate multivariate time-series for 3 channels of length n_samples\n",
    "    from a vector AR(1) model. Uncorrelated white noise channels are\n",
    "    interspersed between the vector sequences.\n",
    "\n",
    "    VAR(1) Model: \n",
    "    y(t+1) = Ay(t) + Bu(t) + err(t)\n",
    "    \"\"\"\n",
    "    n_chs = 3\n",
    "    n_noise_chs = 3\n",
    "    \n",
    "    # scale data along time w/ normalization\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    A = np.array([\n",
    "        [0.5,  0.5*k, 0.7*k],\n",
    "        [0.3*k, -0.8, -0.15*k],\n",
    "        [0.5*k,  0.2*k, -0.6],\n",
    "    ])\n",
    "        \n",
    "    # signal that separates binary classes\n",
    "    if cls == 0:\n",
    "        B = np.array([\n",
    "            [  0.5,  0.1*k, 0.1*k],\n",
    "            [0, 0.5, 0.1*k],\n",
    "            [0,  0, -0.6]\n",
    "        ])\n",
    "    elif cls == 1:\n",
    "        B = np.array([\n",
    "            [  0.5,  0, 0],\n",
    "            [0, 0.5, 0],\n",
    "            [0,  0, -0.6]\n",
    "        ])\n",
    "    \n",
    "    # create DT Linear system\n",
    "    linsys = DiscreteLinearSystem(A=A, B=B)\n",
    "    \n",
    "    # generate input\n",
    "    ut = _generate_random_input_pulse(n_chs, n_steps)\n",
    "    \n",
    "    # generate random initial condition and simulate what system would look like\n",
    "    x0 = np.random.random((n_chs,))\n",
    "    y = linsys.reconstruct(x0, ut, steps=n_steps, add_noise=False)\n",
    "    assert y.shape == (n_chs, n_steps)\n",
    "    \n",
    "    # add iid noise to the system simulation\n",
    "    y_noise = np.random.normal(scale=0.5, size=(n_noise_chs, n_steps))  # add Gaussian noise?\n",
    "    # print(f\"max: {np.max(y)}, min: {np.min(y)}\")\n",
    "    y = y + y_noise\n",
    "    \n",
    "    # stack noise \n",
    "    y_noise = np.random.random((n_noise_chs, n_steps))\n",
    "    y = np.vstack((\n",
    "        y[0,:], y_noise[0,:],\n",
    "        y[1,:], y_noise[1,:],\n",
    "        y[2,:], y_noise[2,:]\n",
    "    ))\n",
    "    \n",
    "    # normalize along the time domain\n",
    "    # y = scaler.fit_transform(y.T).T\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ar_samples(cls=0, n_steps=1000, k=1):\n",
    "    \"\"\"\n",
    "    Generate multivariate time-series for 3 channsl of length n_samples\n",
    "    from a vector AR(1) model. Noise channels are interleaved between\n",
    "    the vector sequences.\n",
    "\n",
    "    VAR(1) Model: \n",
    "    y(t+1) = Ay(t) + Bu(t) + err(t)\n",
    "\n",
    "    For now, we ignore exogenous variables, i.e. B = 0, and assume\n",
    "    uncorrelated errors.\n",
    "    \"\"\"\n",
    "\n",
    "    n_chs = 3\n",
    "    n_noise_chs = 3\n",
    "\n",
    "    A = np.array([[\n",
    "    [1.0,    0.5,    0.5],\n",
    "    [  0.4, 0.9,    0.5],\n",
    "    [  0.4,    0.4, 0.8]\n",
    "    ]])\n",
    "    if cls == 0:\n",
    "        B = []\n",
    "#     if cls == 0:\n",
    "#         A = np.array([[\n",
    "#             [  0.5,  0.5*k, 0.7*k],\n",
    "#             [0.3*k, -0.8, -0.15*k],\n",
    "#             [0.5*k,  0.2*k, -0.6]\n",
    "#         ]])\n",
    "#     elif cls == 1:\n",
    "#         A = np.array([[\n",
    "#             [1.0,    0.5,    0.5],\n",
    "#             [  0.4, 0.9,    0.5],\n",
    "#             [  0.4,    0.4, 0.8]\n",
    "#         ]])\n",
    "\n",
    "    B = np.zeros((n_chs, n_chs))\n",
    "\n",
    "    A_eigvals = np.linalg.eigvals(A)\n",
    "    A_spec_rad = np.max(np.abs(A_eigvals))\n",
    "\n",
    "    # TODO: Figure out how to best set error relative to A matrix\n",
    "    err_cov = 0.05 * A_spec_rad * np.identity(n_chs)\n",
    "\n",
    "    var = VARProcess(A, B, err_cov, _params_info={'k_trend': 0})\n",
    "    y = var.simulate_var(steps=n_steps).T\n",
    "    assert y.shape == (n_chs, n_steps)\n",
    "\n",
    "    y_noise = np.random.random((n_noise_chs, n_steps))\n",
    "\n",
    "    y = np.vstack((\n",
    "        y[0,:], y_noise[0,:],\n",
    "        y[1,:], y_noise[1,:],\n",
    "        y[2,:], y_noise[2,:]\n",
    "    ))\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(ns, T, nchs=6, cov_factor=1, test_size=0.5, random_state=None):\n",
    "    # initialize data structures for train/test data\n",
    "    X_train, Y_train = np.empty(shape=(0,nchs,T)), np.empty(shape=(0))\n",
    "    X_test, Y_test = np.empty(shape=(0,nchs,T)), np.empty(shape=(0))\n",
    "\n",
    "    # simulate over varying sizes of data sequence\n",
    "    for n in ns:\n",
    "        y = []\n",
    "        X = []\n",
    "\n",
    "        # generate correlated multi-variate time series\n",
    "        for i in range(n):\n",
    "            _x = generate_ar_samples2(cls=0, n_steps=T, k=cov_factor)\n",
    "            X.append(_x)\n",
    "            y.append(0)\n",
    "        for i in range(n):\n",
    "            _x = generate_ar_samples2(cls=1, n_steps=T, k=cov_factor)\n",
    "            X.append(_x)\n",
    "            y.append(1)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # perform training test split\n",
    "        _X_train, _X_test, _y_train, _y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            random_state=random_state)\n",
    "        X_train = np.vstack((X_train, _X_train))\n",
    "        Y_train = np.hstack((Y_train, _y_train))\n",
    "        X_test = np.vstack((X_test, _X_test))\n",
    "        Y_test = np.hstack((Y_test, _y_test))\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100  # number of time steps for each sequence\n",
    "ns = np.array([50,100,200,400,1000,2000])  # length of data sequence\n",
    "nchs = 6  # number of channels in each MTS\n",
    "test_size = 0.5  # size of the test data\n",
    "random_state = 1234  # random state to separate training/testing samples\n",
    "np.random.seed(random_state)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = simulate_data(\n",
    "    ns, T, nchs=nchs, cov_factor=1, test_size=test_size, random_state=random_state\n",
    ")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morfdemo",
   "language": "python",
   "name": "morfdemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
